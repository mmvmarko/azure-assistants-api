{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAI Assistants API with functions\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "# AZURE_OPENAI_API_KEY\n",
    "# AZURE_OPENAI_ENDPOINT\n",
    "# AZURE_OPENAI_API_VERSION\n",
    "# SEARCH_KEY\n",
    "load_dotenv()\n",
    "\n",
    "# Create Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),\n",
    "    api_version=os.getenv('AZURE_OPENAI_API_VERSION')\n",
    ")\n",
    "\n",
    "# assistant ID as created in the portal\n",
    "assistant_id = \"aasst_NjjVJ5GVWXjJLvYvXtmEQsQR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a thread\n",
    "\n",
    "A thread is not linked to the assistant at creation time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread id:  thread_5sdhXFzj4pCruE4627Dp4qAy\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Threads have an id as well\n",
    "print(\"Thread id: \", thread.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a message to the thread\n",
    "\n",
    "The assistant can perform actions like turning a lamp on or off or setting its brightness.\n",
    "\n",
    "The function json can be found in the assistant definition in the Assistant Playgrond.\n",
    "\n",
    "- set_lamp(lamp_id, state)\n",
    "- set_lamp_brightness(lamp_id, brightness)\n",
    "\n",
    "After adding the user message and running the thread, we show information about the run via a json dump.\n",
    "\n",
    "Important: do not wait too long with the other cells because you need to provide a tool response within a certain amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': \"No assistant found with id 'aasst_NjjVJ5GVWXjJLvYvXtmEQsQR'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m message \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     18\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m     19\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m     content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTurn living room lamp and kitchen lamp on. Set both lamps to half brightness.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# create a run \u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43massistant_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43massistant_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# use the assistant id defined in the first cell\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# wait for the run to complete\u001b[39;00m\n\u001b[0;32m     30\u001b[0m run \u001b[38;5;241m=\u001b[39m wait_for_run(run, thread\u001b[38;5;241m.\u001b[39mid)\n",
      "File \u001b[1;32mc:\\Users\\markovu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\resources\\beta\\threads\\runs\\runs.py:110\u001b[0m, in \u001b[0;36mRuns.create\u001b[1;34m(self, thread_id, assistant_id, additional_instructions, instructions, metadata, model, tools, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a non-empty value for `thread_id` but received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mthread_id\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    109\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/threads/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mthread_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/runs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43massistant_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madditional_instructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstructions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRunCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\markovu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:1179\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1167\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1175\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1176\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1177\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1178\u001b[0m     )\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\markovu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:868\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    861\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    866\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    867\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 868\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\markovu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\_base_client.py:959\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    956\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    958\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    962\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    963\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    966\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    967\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': \"No assistant found with id 'aasst_NjjVJ5GVWXjJLvYvXtmEQsQR'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# function returns the run when status is no longer queued or in_progress\n",
    "def wait_for_run(run, thread_id):\n",
    "    while run.status == 'queued' or run.status == 'in_progress':\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "                thread_id=thread_id,\n",
    "                run_id=run.id\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    return run\n",
    "\n",
    "\n",
    "# create a message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Turn living room lamp and kitchen lamp on. Set both lamps to half brightness.\"\n",
    ")\n",
    "\n",
    "# create a run \n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id # use the assistant id defined in the first cell\n",
    ")\n",
    "\n",
    "# wait for the run to complete\n",
    "run = wait_for_run(run, thread.id)\n",
    "\n",
    "# show information about the run\n",
    "# should indicate that run status is requires_action\n",
    "# should contain information about the tools to call\n",
    "print(run.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions to control lamps\n",
    "\n",
    "The search_blog function is a helper function that uses the requests library to search the blog. It returns multiple results via a similarity searh in Azure AI Search.\n",
    "\n",
    "We could query Azure AI Search directly here but the API that is used was already created and running as an Azure Container App."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_error = False\n",
    "\n",
    "\n",
    "def set_lamp(lamp=\"\", state=True):\n",
    "    if make_error:\n",
    "        return \"An error occurred\"\n",
    "    return f\"The {lamp} is {'on' if state else 'off'}\"\n",
    "\n",
    "def set_lamp_brightness(lamp=\"\", brightness=100):\n",
    "    if make_error:\n",
    "        return \"An error occurred\"\n",
    "    return f\"The brightness of the {lamp} is set to {brightness}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if we need to use a tool\n",
    "\n",
    "Below we check if we need to use a tool. We assume we need to here. We are not taking into account a scenario where we do not need to use a tool. In reality, we would need to allow for that scenario.\n",
    "\n",
    "If the assistant indicates we need to use a tool, it will tell use the function name and the arguments to use based on the function definition defined in the assistant. We will then call the search_blog function with the arguments and pass the tool call results back to the assistant.\n",
    "\n",
    "After passing the tool call results, we run the thread again and show the messages via a json dump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls: [RequiredActionFunctionToolCall(id='call_2MhF7oRsIIh3CpLjM7RAuIBA', function=Function(arguments='{\"lamp\": \"living room\", \"state\": true}', name='set_lamp'), type='function'), RequiredActionFunctionToolCall(id='call_SWvFSPllcmVv1ozwRz7mDAD6', function=Function(arguments='{\"lamp\": \"kitchen\", \"state\": true}', name='set_lamp'), type='function'), RequiredActionFunctionToolCall(id='call_auXoTWYehhVQE2YMGOj3bUt0', function=Function(arguments='{\"lamp\": \"living room\", \"brightness\": 50}', name='set_lamp_brightness'), type='function'), RequiredActionFunctionToolCall(id='call_e6ij76rvt70bIhIlwIPVQA2s', function=Function(arguments='{\"lamp\": \"kitchen\", \"brightness\": 50}', name='set_lamp_brightness'), type='function')]\n",
      "Tool outputs submitted\n",
      "Run information:\n",
      "----------------\n",
      "{\n",
      "  \"id\": \"run_ciSrRepgIrly3qoDWEY4LLR0\",\n",
      "  \"assistant_id\": \"asst_Z2YGBjhORYJGyPv6AQ4HugzP\",\n",
      "  \"cancelled_at\": null,\n",
      "  \"completed_at\": 1707478823,\n",
      "  \"created_at\": 1707478745,\n",
      "  \"expires_at\": null,\n",
      "  \"failed_at\": null,\n",
      "  \"file_ids\": [],\n",
      "  \"instructions\": \"You are a home assistant. You can do two things:\\n- turn a lamp on or off\\n- set the brightness of a lamp\\n\\nTo perform the actions, you use the functions at your disposal. When an action fails, never try to run the action again. Leave it up to the user.\\n\\nIf the user says \\\"Turn living room lamp on\\\", the name of the lamp is living room, not living room lamp.\\n\",\n",
      "  \"last_error\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4-preview\",\n",
      "  \"object\": \"thread.run\",\n",
      "  \"required_action\": null,\n",
      "  \"started_at\": 1707478821,\n",
      "  \"status\": \"completed\",\n",
      "  \"thread_id\": \"thread_plwRmKEzRB6ETEABZI1zYBVZ\",\n",
      "  \"tools\": [\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"set_lamp\",\n",
      "        \"description\": \"Turn lamp on or off\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"lamp\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Name of the lamp\"\n",
      "            },\n",
      "            \"state\": {\n",
      "              \"type\": \"boolean\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"lamp\",\n",
      "            \"state\"\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    },\n",
      "    {\n",
      "      \"function\": {\n",
      "        \"name\": \"set_lamp_brightness\",\n",
      "        \"description\": \"Change brightness of a lamp\",\n",
      "        \"parameters\": {\n",
      "          \"type\": \"object\",\n",
      "          \"properties\": {\n",
      "            \"lamp\": {\n",
      "              \"type\": \"string\",\n",
      "              \"description\": \"Name of the lamp\"\n",
      "            },\n",
      "            \"brightness\": {\n",
      "              \"type\": \"integer\",\n",
      "              \"description\": \"Brightness between 0 and 100\"\n",
      "            }\n",
      "          },\n",
      "          \"required\": [\n",
      "            \"lamp\",\n",
      "            \"brightness\"\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      \"type\": \"function\"\n",
      "    }\n",
      "  ]\n",
      "} \n",
      "\n",
      "Messages in the thread:\n",
      "-----------------------\n",
      "{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"id\": \"msg_aEdSPOoWJNuhxRiLMPFSuadO\",\n",
      "      \"assistant_id\": \"asst_Z2YGBjhORYJGyPv6AQ4HugzP\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": {\n",
      "            \"annotations\": [],\n",
      "            \"value\": \"The actions have failed. If you would like to try again or perform another action, please let me know.\"\n",
      "          },\n",
      "          \"type\": \"text\"\n",
      "        }\n",
      "      ],\n",
      "      \"created_at\": 1707478821,\n",
      "      \"file_ids\": [],\n",
      "      \"metadata\": {},\n",
      "      \"object\": \"thread.message\",\n",
      "      \"role\": \"assistant\",\n",
      "      \"run_id\": \"run_ciSrRepgIrly3qoDWEY4LLR0\",\n",
      "      \"thread_id\": \"thread_plwRmKEzRB6ETEABZI1zYBVZ\"\n",
      "    },\n",
      "    {\n",
      "      \"id\": \"msg_wu8p4Y1R4BMrSaY2plA0kRud\",\n",
      "      \"assistant_id\": null,\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"text\": {\n",
      "            \"annotations\": [],\n",
      "            \"value\": \"Turn living room lamp and kitchen lamp on. Set both lamps to half brightness.\"\n",
      "          },\n",
      "          \"type\": \"text\"\n",
      "        }\n",
      "      ],\n",
      "      \"created_at\": 1707478745,\n",
      "      \"file_ids\": [],\n",
      "      \"metadata\": {},\n",
      "      \"object\": \"thread.message\",\n",
      "      \"role\": \"user\",\n",
      "      \"run_id\": null,\n",
      "      \"thread_id\": \"thread_plwRmKEzRB6ETEABZI1zYBVZ\"\n",
      "    }\n",
      "  ],\n",
      "  \"object\": \"list\",\n",
      "  \"first_id\": \"msg_aEdSPOoWJNuhxRiLMPFSuadO\",\n",
      "  \"last_id\": \"msg_wu8p4Y1R4BMrSaY2plA0kRud\",\n",
      "  \"has_more\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# we only check for required_action here\n",
    "# required action means we need to call a tool\n",
    "if run.required_action:\n",
    "    # get tool calls and print them\n",
    "    # check the output to see what tools_calls contains\n",
    "    tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "    print(\"Tool calls:\", tool_calls)\n",
    "\n",
    "    # we might need to call multiple tools\n",
    "    # the assistant API supports parallel tool calls\n",
    "    # we account for this here although we only have one tool call\n",
    "    tool_outputs = []\n",
    "    for tool_call in tool_calls:\n",
    "        func_name = tool_call.function.name\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        # call the function with the arguments provided by the assistant\n",
    "        if func_name == \"set_lamp\":\n",
    "            result = set_lamp(**arguments)\n",
    "        elif func_name == \"set_lamp_brightness\":\n",
    "            result = set_lamp_brightness(**arguments)\n",
    "\n",
    "        # append the results to the tool_outputs list\n",
    "        # you need to specify the tool_call_id so the assistant knows which tool call the output belongs to\n",
    "        tool_outputs.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"output\": json.dumps(result)\n",
    "        })\n",
    "\n",
    "    # now that we have the tool call outputs, pass them to the assistant\n",
    "    run = client.beta.threads.runs.submit_tool_outputs(\n",
    "        thread_id=thread.id,\n",
    "        run_id=run.id,\n",
    "        tool_outputs=tool_outputs\n",
    "    )\n",
    "\n",
    "    print(\"Tool outputs submitted\")\n",
    "\n",
    "    # now we wait for the run again\n",
    "    run = wait_for_run(run, thread.id)\n",
    "else:\n",
    "    print(\"No tool calls identified\\n\")\n",
    "\n",
    "# show information about the run\n",
    "print(\"Run information:\")\n",
    "print(\"----------------\")\n",
    "print(run.model_dump_json(indent=2), \"\\n\")\n",
    "\n",
    "# now print all messages in the thread\n",
    "print(\"Messages in the thread:\")\n",
    "print(\"-----------------------\")\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "print(messages.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 Turn living room lamp and kitchen lamp on. Set both lamps to half brightness. \n",
      "\n",
      "🤖 The actions have failed. If you would like to try again or perform another action, please let me know. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "messages_json = json.loads(messages.model_dump_json())\n",
    "\n",
    "def role_icon(role):\n",
    "    if role == \"user\":\n",
    "        return \"👤\"\n",
    "    elif role == \"assistant\":\n",
    "        return \"🤖\"\n",
    "\n",
    "for item in reversed(messages_json['data']):\n",
    "    # Check the content array\n",
    "    for content in reversed(item['content']):\n",
    "        # If there is text in the content array, print it\n",
    "        if 'text' in content:\n",
    "            print(role_icon(item[\"role\"]),content['text']['value'], \"\\n\")\n",
    "        # If there is an image_file in the content, print the file_id\n",
    "        if 'image_file' in content:\n",
    "            print(\"Image ID:\" , content['image_file']['file_id'], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
